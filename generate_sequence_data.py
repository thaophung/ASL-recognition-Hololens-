import os
import numpy as np
import random
import scipy.misc

def get_data_list(data_path):
    '''
    Input parameters:
        list_dir: 
        video_dir:

    Return value:
        val_data/train_data: list of tuples(clip_dir, class_index)
        class_index: dictionary of mapping (class_name -> class_index)
    '''

    train_dir = os.path.join(data_path, 'train')
    val_dir = os.path.join(data_path, 'val')

    vallisttxt = 'vallist_optical.txt'
    trainlisttxt = 'trainlist_optical.txt'

    vallist = []
    txt_path = os.path.join(data_path, vallisttxt)
    with open(txt_path) as fo:
        for line in fo:
            vallist.append(line[:line.rfind(' ')])

    trainlist = []
    txt_path = os.path.join(data_path, trainlisttxt)
    with open(txt_path) as fo:
        for line in fo:
            trainlist.append(line[:line.rfind(' ')])

    class_index = dict()
    class_dir = os.path.join(data_path, 'classInd.txt')
    with open(class_dir) as fo:
        for line in fo:
            class_number, class_name = line.split()
            class_number = int(class_number)
            class_index[class_name] = class_number

    train_data = []
    for i, clip in enumerate(trainlist):
        clip_class = os.path.dirname(clip)
        dst_dir = os.path.join(train_dir, clip)
        train_data.append((dst_dir, class_index[clip_class]))

    val_data = []
    for i, clip in enumerate(vallist):
        clip_class = os.path.dirname(clip)
        dst_dir = os.path.join(val_dir, clip)
        val_data.append((dst_dir, class_index[clip_class]))

    return train_data, val_data, class_index


def sequence_generator(data_list, batch_size, input_shape, num_classes):
    '''
    Read sequence data of batch_size into memory
    :param: data_list: The data generated by get_data_list
    :param: batch_size
    :param input_shape: tuple: the shape of numpy ndarray, 
        e.g. (seq_len, 216, 216, 3) for sequence
        or (216, 216, 18) for optical flow data
    :param num_classes:
    :return:
    '''

    if isinstance(input_shape, tuple):
        x_shape = (batch_size,) + input_shape
    else:
        raise ValueError('Input shape is neither 1D or 3D')

    y_shape = (batch_size, num_classes)
    index = 0
    while True:
        batch_x = np.ndarray(x_shape)
        batch_y = np.zeros(y_shape)
        #print(batch_size)
        for i in range(0, batch_size):
            step = random.randrange(0, len(data_list) - 1)    # approach a random-size step to get the next video sample
            #print('step: ' + str(step))
            index = (index+step) % len(data_list)
            clip_dir, clip_class = data_list[index]
#            print('index: ' + str(index))
#            print(clip_dir)
            batch_y[i, clip_class-1] = 1
            #clip_dir = os.path.splitext(clip_dir)[0] + '.npy'
            # avoid endless loop
            count = 0
            while not os.path.exists(clip_dir):
                count += 1
                if count > 20:
                    raise FileExistsError('Too many file missing')
                index = (index + 1) % len(data_list)
                clip_dir, class_idx = data_list[index]
            clip_data = np.load(clip_dir)
#            print(clip_data.shape)
#            print(batch_x.shape)
            if clip_data.shape != batch_x.shape[1:]:
                print(clip_dir)
                raise ValueError('The number of time sequence is inconsistent with the video data')
            batch_x[i] =clip_data
        yield batch_x, batch_y

def image_from_sequence_generator(data_list, batch_size, input_shape, num_classes):
    '''
        Read one frame in the sequence data in memory
        input_shape: (seq_len,) + img_size
    '''
    batch_image_shape = (batch_size,) + input_shape[1:]

    batch_image = np.ndarray(batch_image_shape)

    video_gen = sequence_generator(data_list, batch_size, input_shape, num_classes)

    while True:
        batch_video, batch_label = next(video_gen)
        for idx, video in enumerate(batch_video):
            sample_frame_idx = random.randint(0, input_shape[0] - 1)
            sample_frame = video[sample_frame_idx]
            batch_image[idx] = sample_frame

        yield batch_image, batch_label


